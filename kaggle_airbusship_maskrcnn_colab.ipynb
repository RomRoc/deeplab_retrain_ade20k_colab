{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kaggle_airbusship_maskrcnn_colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "5ojo-R7bBKjy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "LSd8Mb6d4NoC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Colab (Jupyter) notebook for Kaggle Airbus Ship detection competition, based on Matterport Mask R-CNN"
      ]
    },
    {
      "metadata": {
        "id": "1Rs_5HV-iDJv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Results:\n",
        "*   0.653 starting model with deepretina augmentation\n",
        "*   RPN_ANCHOR_SCALES = (8,16,32,64,128) 0.598, so keep default \n",
        "* 0.658 with default augmentation, with clean_mask\n",
        "* 0.655 with default augmentation, without clean_mask, and Adam optimizer\n",
        "* 0.670 train with default augmentation and 400 STEPS_PER_EPOCH\n",
        "* 0.680 without clean_mask and default augmentation and 400 STEPS_PER_EPOCH, from now without CLEAN_MASK\n",
        "* 0.687 with iafoss classification file\n",
        "* from skimage.morphology import dilation, erosion: 0.683->0.669\n",
        "* from skimage.morphology import dilation: 0.694->0.685\n",
        "* val set not only 0.jpg images, but even 1.jpg: 0.683->0.688\n",
        "* results 300 steps, 10 epochs: adam amsgrad: 0.662, sgd: 0.679, adamax: 0.683, adamax retrained 600 steps, 10 epochs, lr 0.00001 and 0.000001: 0.687\n",
        "* detect with lower val_mrcnn_mask_loss model value instead of with last trained model doesn't increase result\n",
        "* sgd, 300 steps, epochs lr 10 0.001 10 0.0001 10 0.00001 10 0.000001: 0.679. Retrained 300 steps. epochs lr 10 0.0001 20 0.00001 10 0.000001: 0.694\n",
        "* binary_fill_holes doesnt change anything\n",
        "* dropping predicted object masks smaller than 50 pixels, between 50 and 1000 pixels apply the mask minimal rectangle (neptune): 0.694->0.690\n",
        "* DETECTION_MIN_CONFIDENCE = 0.9: 0.694, 0.8: 0.683; 0.95: 0.670, 0.88:0.694, 0.85: 0.687\n",
        "* retrain from 0.694 30 epochs 300 step: lr=10^-5: 0.607\n",
        "* DETECTION_NMS_THRESHOLD = 0.1->0.2: 0.694->0.695, 0.2->0.3: 0.698->0.698, 0.2->0.0: 0.698->0.700\n",
        "* retrain from 0.694, 10 epochs x 400 steps x lr 10^-4 10^-5 10^-6: 0.694->0.691 \n",
        "* retrain from 0.694, 20 epochs x 300 steps x lr 10^-5 10^-6: very low, maybe overfitting\n",
        "* retrain without iaa.GaussianBlur(sigma=(0.0, 5.0)), set SomeOf(0, 5), 10 epochs x 300 steps x lr 10^-4 10^-5 10^-6: 0.694->0.697\n",
        "* retrain without iaa.GaussianBlur(sigma=(0.0, 5.0)), 10 epochs x 300 steps x lr 10^-4 10^-5 10^-6: 0.694->0.698\n",
        "* remove prediction ships <= 50 pixels, doesn't change result\n",
        "* POST_NMS_ROIS_INFERENCE 1000-> 2000, doesn't change result\n",
        "* retrain from 0.700, 300 steps, 10 epochs 10^-4, 20 10^-5, 10 10^-6: 0.689\n",
        "* cluster_prediction of mirzaevinom, combined predictions on actual image and horizontally flipped: MIN_CONFIDENCE = 0.9: 0.700->0.696, 0.85: 0.687->0.689\n",
        "* RPN_ANCHOR_SCALES 8,16,32,64,128: 0.700->0.672 - 16, 32, 64, 128, 256: 0.700->0.634\n",
        "* trained only with lr 10^-4 and 10^-5 (not 10^-6): 0.700->0.668\n",
        "* trained from 0.700: 300, 30, 10^-4 10^-5 10^-6: 0.696\n",
        "* trained from 0.695: 400, 30, 10^-4 10^-5 10^-6: 0.693\n",
        "* trained from 0.700: 300, 10, 10^-7: very low, maybe overfitting\n",
        "* tta lr ud: 0.95: only lr 0.699, even ud:0.699, 0.94:0.700, 0.93:0.700\n",
        "* image augmentation from kaggle hmendonca airbus, 10^-5 10^6 very low, maybe overfitting\n",
        "* image augmentation from kaggle hmendonca airbus, 10^-4 10^-5 10^6: 0-700->0.697\n",
        "* add to training set 3-5k images without ships:0.700->0.687\n",
        "* delete prediction big shape not sharp(rotated_bounding_box): l1+l2, l1/l2: 150, 2.3: 0.701 - 120, 2.3: 0.700 - 150, 2.0: 0.701\n",
        "* 8-tta merge_cluster_prediction: 0.701->0.704\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Todo:\n",
        "* pretty much every high scoring team used the lovasz hinge loss to increase their score after first training with BCE or focal\n",
        "* adaboost\n",
        "* Split (using stratification) train and val dataset\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "B9beTnKV-qLK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ls /root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kCOnBfapZG1W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Requirements"
      ]
    },
    {
      "metadata": {
        "id": "Azg5mZBCwiUm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "from google.colab import files\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = os.path.expanduser(\"~/.kaggle/kaggle.json\")\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39Wtm53bG7xW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "!git clone --quiet https://github.com/matterport/Mask_RCNN.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZY2h5buS9xb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd Mask_RCNN\n",
        "\n",
        "!pip install kaggle\n",
        "!pip install imgaug\n",
        "!pip install -q PyDrive\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install\n",
        "\n",
        "%cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V8MfuZYuwspF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c airbus-ship-detection\n",
        "\n",
        "!unzip -q -d train train_v2.zip\n",
        "!unzip -q train_ship_segmentations_v2.csv.zip\n",
        "\n",
        "!mkdir test\n",
        "!mkdir test/ship\n",
        "!mkdir test/noship\n",
        "!unzip -q -d test/noship test_v2.zip\n",
        "\n",
        "!rm *.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBYZlrKNPLS3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "os.remove('train/6384c3e78.jpg')\n",
        "\n",
        "delete_files =  []\n",
        "for f in delete_files:\n",
        "  os.remove('/root/test/noship/'+f)\n",
        "\n",
        "traindatadir = '/root/train/'\n",
        "df = pd.read_csv('train_ship_segmentations_v2.csv')\n",
        "print('Move',df['ImageId'].nunique(),'file')\n",
        "\n",
        "ship_dir = traindatadir + 'ship'\n",
        "os.mkdir(ship_dir)\n",
        "dfNotNull = df[df.EncodedPixels.notnull()]\n",
        "imageIdsShip = dfNotNull['ImageId'].unique()\n",
        "for file_name in imageIdsShip:\n",
        "  shutil.move(traindatadir + file_name, ship_dir)\n",
        "print('Moved in',ship_dir,imageIdsShip.size,'file')\n",
        "\n",
        "#for file_name in glob.glob(traindatadir+\"/*5.jpg\"):\n",
        "#  shutil.move(file_name, ship_dir)\n",
        "\n",
        "noship_dir = traindatadir + 'noship'\n",
        "os.mkdir(noship_dir)\n",
        "for file_name in glob.glob(traindatadir+\"/*.jpg\"):\n",
        "  shutil.move(file_name, noship_dir)\n",
        "print('Moved in',noship_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rs-PQ1G5zNG9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model_file = 'Mask_RCNN/mrcnn/model.py'\n",
        "\n",
        "#with open(model_file, 'r') as file:\n",
        "#  filedata = file.read()\n",
        "\n",
        "#filedata = filedata.replace('SGD', 'Adamax')\n",
        "#filedata = filedata.replace('momentum=momentum,', '')\n",
        "#filedata = filedata.replace('SGD', 'Adam')\n",
        "#filedata = filedata.replace('momentum=momentum', 'amsgrad=True')\n",
        "\n",
        "#with open(model_file, 'w') as file:\n",
        "#  file.write(filedata)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-wFbHoM-OZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ROOT_DIR = os.path.abspath(\"/root/\")\n",
        "MASKRCNN_DIR = os.path.join(ROOT_DIR, \"Mask_RCNN/\")\n",
        "DATASET_DIR = os.path.join(ROOT_DIR, \".\")\n",
        "TRAIN_DIR = os.path.join(ROOT_DIR, \"train\")\n",
        "TRAIN_SHIP_DATASET_DIR = os.path.join(ROOT_DIR, \"train/ship/\")\n",
        "TEST_DIR = os.path.join(ROOT_DIR, \"test/\")\n",
        "SHIP_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_ship.h5\")\n",
        "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "RESULTS_DIR = os.path.join(ROOT_DIR, \"results\")\n",
        "\n",
        "import sys\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "sys.path.append(MASKRCNN_DIR)\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from skimage.data import imread\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "from mrcnn.config import Config\n",
        "from mrcnn import utils\n",
        "from mrcnn import visualize\n",
        "from mrcnn import model as modellib\n",
        "\n",
        "val_image_ids = []\n",
        "for file_name in glob.glob(os.path.join(TRAIN_SHIP_DATASET_DIR,\"*0.jpg\")) + glob.glob(os.path.join(TRAIN_SHIP_DATASET_DIR,\"*1.jpg\")):\n",
        "  val_image_ids.append(os.path.splitext(os.path.basename(file_name))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6IYa1e2mYYGv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ShipConfig(Config):\n",
        "    NAME = \"ship\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 1 + 1  # Background + ship\n",
        "    IMAGE_MIN_DIM = 768\n",
        "    IMAGE_MAX_DIM = 768\n",
        "    TRAIN_ROIS_PER_IMAGE = 512\n",
        "    STEPS_PER_EPOCH = 300\n",
        "    RPN_TRAIN_ANCHORS_PER_IMAGE = 320\n",
        "#    RPN_ANCHOR_SCALES = (8,16,32,64,128)\n",
        "    \n",
        "class InferenceConfig(Config):\n",
        "    NAME = \"ship\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    NUM_CLASSES = 1 + 1  # Background + ship\n",
        "    IMAGE_MIN_DIM = 768\n",
        "    IMAGE_MAX_DIM = 768\n",
        "    TRAIN_ROIS_PER_IMAGE = 512\n",
        "    MAX_GT_INSTANCES = 20\n",
        "    DETECTION_MIN_CONFIDENCE = 0.9\n",
        "    DETECTION_NMS_THRESHOLD = 0.0\n",
        "    DETECTION_MAX_INSTANCES = 10\n",
        "\n",
        "\n",
        "############################################################\n",
        "#  Dataset\n",
        "############################################################\n",
        "\n",
        "class ShipDataset(utils.Dataset):\n",
        "\n",
        "    def load_ship(self, dataset_dir, subset):\n",
        "        \"\"\"Load a subset of the ship dataset.\n",
        "\n",
        "        dataset_dir: Root directory of the dataset\n",
        "        subset: Subset to load. Either the name of the sub-directory,\n",
        "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
        "                * train: stage1_train excluding validation images\n",
        "                * val: validation images from val_image_ids\n",
        "        \"\"\"\n",
        "        # Add classes. We have one class.\n",
        "        # Naming the dataset ship, and the class ship\n",
        "        self.add_class(\"ship\", 1, \"ship\")\n",
        "\n",
        "        # Which subset?\n",
        "        # \"val\": use hard-coded list above\n",
        "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
        "        # else: use the data from the specified sub-directory\n",
        "        assert subset in [\"train\", \"val\", \"test\"]\n",
        "        subset_dir = \"train\" if subset in [\"train\", \"val\"] else subset\n",
        "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
        "        image_ids = []\n",
        "        if subset == \"val\":\n",
        "            image_ids = val_image_ids\n",
        "        elif subset == \"train\":\n",
        "            # Get image ids from directory names\n",
        "            masks_count = masks.groupby(['ImageId'], as_index=False).count()\n",
        "            masks_toget = masks_count.loc[masks_count['EncodedPixels'] >= 1]['ImageId']\n",
        "            for filename in masks_toget:\n",
        "                image_ids.append(os.path.splitext(filename)[0])\n",
        "            image_ids = list(set(image_ids) - set(val_image_ids))\n",
        "        else:\n",
        "            for filename in next(os.walk(dataset_dir))[2]:\n",
        "                image_ids.append(os.path.splitext(filename)[0])\n",
        "        image_ids.sort()\n",
        "        # Add images\n",
        "        for image_id in image_ids:\n",
        "            self.add_image(\n",
        "                \"ship\",\n",
        "                image_id=image_id,\n",
        "                path=os.path.join(dataset_dir, \"{}.jpg\".format(image_id)))\n",
        "        print('Dataset size:', len(image_ids))\n",
        "\n",
        "        \n",
        "    def load_mask(self, image_id):\n",
        "        image_file = \"{}.jpg\".format(dataset.image_info[image_id]['id'])\n",
        "        img_masks = masks.loc[masks['ImageId'] == image_file, 'EncodedPixels'].tolist()\n",
        "        shape_mask = (768,768)\n",
        "        \n",
        "        mask = []\n",
        "        for img in [x for x in img_masks if not pd.isnull(x)]:\n",
        "            m = rle_decode(img, shape_mask)\n",
        "            mask.append(m)\n",
        "        if (len(mask) > 0):\n",
        "            mask = np.stack(mask, axis=-1)\n",
        "        else:\n",
        "            mask = np.array([])\n",
        "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
        "        \n",
        "        \n",
        "    def image_reference(self, image_id):\n",
        "        \"\"\"Return the path of the image.\"\"\"\n",
        "        info = self.image_info[image_id]\n",
        "        if info[\"source\"] == \"ship\":\n",
        "            return info[\"id\"]\n",
        "        else:\n",
        "            super(self.__class__, self).image_reference(image_id)\n",
        "\n",
        "\n",
        "\n",
        "############################################################\n",
        "#  RLE Encoding\n",
        "############################################################\n",
        "\n",
        "def rle_encode(mask):\n",
        "    \"\"\"Encodes a mask in Run Length Encoding (RLE).\n",
        "    Returns a string of space-separated values.\n",
        "    \"\"\"\n",
        "    assert mask.ndim == 2, \"Mask must be of shape [Height, Width]\"\n",
        "    # Flatten it column wise\n",
        "    m = mask.T.flatten()\n",
        "    # Compute gradient. Equals 1 or -1 at transition points\n",
        "    g = np.diff(np.concatenate([[0], m, [0]]), n=1)\n",
        "    # 1-based indicies of transition points (where gradient != 0)\n",
        "    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1\n",
        "    # Convert second index in each pair to lenth\n",
        "    rle[:, 1] = rle[:, 1] - rle[:, 0]\n",
        "    return \" \".join(map(str, rle.flatten()))\n",
        "\n",
        "\n",
        "def rle_decode(rle, shape):\n",
        "    \"\"\"Decodes an RLE encoded list of space separated\n",
        "    numbers and returns a binary mask.\"\"\"\n",
        "    rle = list(map(int, rle.split()))\n",
        "    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])\n",
        "    rle[:, 1] += rle[:, 0]\n",
        "    rle -= 1\n",
        "    mask = np.zeros([shape[0] * shape[1]], np.bool)\n",
        "    for s, e in rle:\n",
        "        assert 0 <= s < mask.shape[0]\n",
        "        assert 1 <= e <= mask.shape[0], \"shape: {}  s {}  e {}\".format(shape, s, e)\n",
        "        mask[s:e] = 1\n",
        "    # Reshape and transpose\n",
        "    mask = mask.reshape([shape[1], shape[0]]).T\n",
        "    return mask\n",
        "\n",
        "\n",
        "def mask_to_rle(image_id, mask, scores):\n",
        "    \"Encodes instance masks to submission format.\"\n",
        "    assert mask.ndim == 3, \"Mask must be [H, W, count]\"\n",
        "    # If mask is empty, return line with image ID only\n",
        "    if mask.shape[-1] == 0:\n",
        "        return \"{},\".format(image_id)\n",
        "    # Remove mask overlaps\n",
        "    # Multiply each instance mask by its score order\n",
        "    # then take the maximum across the last dimension\n",
        "    order = np.argsort(scores)[::-1] + 1  # 1-based descending\n",
        "    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)\n",
        "    # Loop over instance masks\n",
        "    lines = []\n",
        "    for o in order:\n",
        "        m = np.where(mask == o, 1, 0)\n",
        "        # Skip if empty\n",
        "        if m.sum() == 0.0:\n",
        "            continue\n",
        "        rle = rle_encode(m)\n",
        "        lines.append(\"{}, {}\".format(image_id, rle))\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ojo-R7bBKjy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Train"
      ]
    },
    {
      "metadata": {
        "id": "YrBef0VlXrd7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "\n",
        "import shutil\n",
        "\n",
        "for filename in glob.glob(os.path.join(TRAIN_SHIP_DATASET_DIR, '*.*')):\n",
        "  shutil.copy(filename, TRAIN_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xf6WkU-GxE5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "\n",
        "train = os.listdir(TRAIN_SHIP_DATASET_DIR)\n",
        "print(len(train), 'train+val image files with ship')\n",
        "print('val image files', len(val_image_ids))\n",
        "\n",
        "masks = pd.read_csv('./train_ship_segmentations_v2.csv')\n",
        "print(masks['ImageId'].value_counts().shape[0], 'images found in csv, an image can have multiple masks for multiple ship, or not ship (NaN EncodedPixels)')\n",
        "print(masks['EncodedPixels'].value_counts().shape[0], 'ships in train images')\n",
        "print(masks.shape[0], 'masks found in csv, included NaN EncodedPixels for images without ship')\n",
        "\n",
        "masks_count = masks.groupby(['ImageId'], as_index=False).count()\n",
        "print(len(masks_count.loc[masks_count['EncodedPixels'] == 1]['ImageId']), 'images with zero or one mask')\n",
        "\n",
        "masks.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eOJbtYrSBkn4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "############################################################\n",
        "#  Training\n",
        "############################################################\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "def train(model, dataset_dir, subset):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    # Training dataset.\n",
        "    dataset_train = ShipDataset()\n",
        "    dataset_train.load_ship(dataset_dir, subset)\n",
        "    dataset_train.prepare()\n",
        "\n",
        "    # Validation dataset\n",
        "    dataset_val = ShipDataset()\n",
        "    dataset_val.load_ship(dataset_dir, \"val\")\n",
        "    dataset_val.prepare()\n",
        "\n",
        "# Default Image augmentation\n",
        "    augmentation = iaa.SomeOf((0, 2), [\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Flipud(0.5),\n",
        "        iaa.OneOf([iaa.Affine(rotate=90),\n",
        "                   iaa.Affine(rotate=180),\n",
        "                   iaa.Affine(rotate=270)]),\n",
        "        iaa.Multiply((0.8, 1.5))\n",
        "    ])\n",
        "\n",
        "# Deepretina\n",
        "#    augmentation = iaa.Sequential([\n",
        "#        iaa.Fliplr(0.5),\n",
        "#        iaa.Flipud(0.5),\n",
        "#        iaa.OneOf([iaa.Affine(rotate=0),\n",
        "#                   iaa.Affine(rotate=90),\n",
        "#                   iaa.Affine(rotate=180),\n",
        "#                   iaa.Affine(rotate=270)]),\n",
        "#        iaa.Sometimes(0.5,iaa.Affine(rotate=(-10,10))),\n",
        "#        iaa.Add((-15, 15), per_channel=1)\n",
        "#    ])\n",
        "    \n",
        "    lr = 10**-3\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*1,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "        \n",
        "    lr = 10**-4\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*2,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    \n",
        "    lr = 10**-5\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*3,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "\n",
        "    lr = 10**-6\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*4,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    \n",
        "    \n",
        "    lr = 10**-4\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*5,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    \n",
        "    lr = 10**-5\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*7,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "\n",
        "    lr = 10**-6\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*8,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "\n",
        "\n",
        "    lr = 10**-4\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*9,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "    \n",
        "    lr = 10**-5\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*10,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "\n",
        "    lr = 10**-6\n",
        "    print(\"TRAIN WITH LEARNING_RATE\", lr)\n",
        "    model.train(dataset_train, dataset_val,\n",
        "                learning_rate=lr,\n",
        "                epochs=EPOCHS*11,\n",
        "                augmentation=augmentation,\n",
        "                layers='all')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JvN_vCGARSUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = ShipDataset()\n",
        "# The subset is the name of the sub-directory, such as stage1_train,\n",
        "# stage1_test, ...etc. You can also use these special values:\n",
        "#     train: loads stage1_train but excludes validation images\n",
        "#     val: loads validation images from stage1_train. For a list\n",
        "#          of validation images see ship.py\n",
        "dataset.load_ship(DATASET_DIR, subset=\"train\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Xq7z_TBUcMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load and display random samples\n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMbrv5nK3En_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TO START FROM MY PRETRAINED MODEL, UNCOMMENT 2 LAST LINES\n",
        "\n",
        "%cd\n",
        "\n",
        "modelFileId = '1hvp1gy4zEKwpMzfd6pBagNbpgVz4reLu'\n",
        "modelFilePath = 'mask_rcnn_ship.h5'\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': modelFileId})\n",
        "downloaded.GetContentFile(modelFilePath)\n",
        "print('Files downloaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r5a1h6c1VDfH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weights_path = SHIP_WEIGHTS_PATH\n",
        "print(weights_path)\n",
        "\n",
        "config = ShipConfig()\n",
        "if not os.path.exists(weights_path):\n",
        "    print(\"Downloading weights\")\n",
        "    utils.download_trained_weights(weights_path)\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "print(\"Loading weights \", weights_path)\n",
        "model.load_weights(weights_path, by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\"mrcnn_bbox\", \"mrcnn_mask\"])\n",
        "\n",
        "train(model=model, dataset_dir=DATASET_DIR, subset=\"train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "flVl3gHK0GzO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "last_weights_path = sorted(glob.glob(\"/root/logs/*/mask_rcnn_*.h5\"))[-1]\n",
        "print(last_weights_path)\n",
        "\n",
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "    }\n",
        "    media = MediaFileUpload(path, \n",
        "                    mimetype='application/octet-stream',\n",
        "                    resumable=True)\n",
        "    created = drive_service.files().create(body=file_metadata,\n",
        "                                   media_body=media,\n",
        "                                   fields='id').execute()\n",
        "    return created\n",
        "\n",
        "created = save_file_to_drive('mask_rcnn_ship.h5', last_weights_path)\n",
        "modelDriveId = created.get('id')\n",
        "print('File ID: {}'.format(modelDriveId))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o4zyRBl1BpI0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Detect"
      ]
    },
    {
      "metadata": {
        "id": "27BJvOjvq_vE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "\n",
        "#modelFileId = '1hvp1gy4zEKwpMzfd6pBagNbpgVz4reLu' #0.700\n",
        "modelFileId = modelDriveId\n",
        "modelFilePath = 'mask_rcnn_ship.h5'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id': modelFileId})\n",
        "downloaded.GetContentFile(modelFilePath)\n",
        "print('Files downloaded')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ezrLsQu_Wrq4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd\n",
        "\n",
        "inferenceClassificationId = '1uMpxrf_7_Vx4QIt9uxJ5k2_skluf-lMV'\n",
        "inferenceClassificationPath = 'inference_classification.csv'\n",
        "\n",
        "downloaded = drive.CreateFile({'id': inferenceClassificationId})\n",
        "downloaded.GetContentFile(inferenceClassificationPath)\n",
        "print('Files downloaded')\n",
        "\n",
        "import shutil\n",
        "\n",
        "df = pd.read_csv(inferenceClassificationPath)\n",
        "files_ship = df[df.prediction == 'ship']\n",
        "for filename in files_ship.filename:\n",
        "  shutil.copy(os.path.join(TEST_DIR, 'noship', filename), TEST_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VuyGXnyKwoM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#%cd\n",
        "\n",
        "#cropClassificationId = '1Ny12X2plITsrrEd1WdAwo_q2X8I1AZ6a'\n",
        "#cropClassificationPath = 'crop_classification.csv'\n",
        "\n",
        "#downloaded = drive.CreateFile({'id': cropClassificationId})\n",
        "#downloaded.GetContentFile(cropClassificationPath)\n",
        "#print('Files downloaded')\n",
        "\n",
        "\n",
        "#class_imgs_crop = pd.read_csv(cropClassificationPath)\n",
        "\n",
        "#def clean_mask(masks, image_file): #masks = [H, W, N] instance binary masks\n",
        "#  windows_to_crop = class_imgs_crop[(class_imgs_crop['predict']==0) & (class_imgs_crop['orig_filename']==image_file) & (class_imgs_crop['filename'].str.len()==15)]\n",
        "#  clean_matrix = np.ones((masks.shape))\n",
        "#  for row in windows_to_crop.itertuples():\n",
        "#    crop_num = int(row.filename[-1])\n",
        "#    if crop_num == 1:\n",
        "#      clean_matrix[0:368,0:368,:] = 0\n",
        "#    if crop_num == 2:\n",
        "#      clean_matrix[0:368,400:,:]  = 0\n",
        "#    if crop_num == 3:\n",
        "#      clean_matrix[400:,0:368,:]  = 0\n",
        "#    if crop_num == 4:\n",
        "#      clean_matrix[400:,400:,:]   = 0\n",
        "#  masks = np.multiply(masks, clean_matrix)\n",
        "#  return masks\n",
        "\n",
        "\n",
        "#DROP_SIZE = 50\n",
        "#MID_MIN_SIZE = 50\n",
        "#MID_MAX_SIZE = 1000\n",
        "\n",
        "#import cv2\n",
        "\n",
        "#def mask_to_bbox(mask):\n",
        "#    img_box = np.zeros_like(mask)\n",
        "#    _, cnt, _ = cv2.findContours(mask, 1, 2)\n",
        "#    rect = cv2.minAreaRect(cnt[0])\n",
        "#    box = cv2.boxPoints(rect)\n",
        "#    box = np.int0(box)\n",
        "#    cv2.drawContours(img_box, [box], 0, 1, -1)\n",
        "#    return img_box\n",
        "\n",
        "#def mask_postprocessing(masks, image_file): #masks = [H, W, N] instance binary masks\n",
        "#  h, w, n = masks.shape\n",
        "#  for i in range(n):\n",
        "#    mask  = masks[:,:,i]\n",
        "#    size = np.count_nonzero(mask)\n",
        "#    if (size <= DROP_SIZE):\n",
        "#      print('DROP', image_file, i, size)\n",
        "#      masks[:,:,i] = np.zeros((h, w))\n",
        "#    elif MID_MIN_SIZE < size < MID_MAX_SIZE:\n",
        "#      print('MID', image_file, i, size)\n",
        "#      masks[:,:,i] = mask_to_bbox(mask.astype(np.uint8))\n",
        "#  return masks\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WrcIHkyKSjt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ensemble_prediction(model, image):\n",
        "\n",
        "    \"\"\" Test time augmentation method using non-maximum supression\"\"\"\n",
        "\n",
        "    masks = []\n",
        "    scores = []\n",
        "    boxes = []\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    result = model.detect([image], verbose=0)[0]\n",
        "    masks.append(result['masks'])\n",
        "    scores.append(result['scores'])\n",
        "    boxes.append(utils.extract_bboxes(result['masks']))\n",
        "\n",
        "    temp_img = np.fliplr(image)\n",
        "    result = model.detect([temp_img], verbose=0)[0]\n",
        "    mask = np.fliplr(result['masks'])\n",
        "    masks.append(mask)\n",
        "    scores.append(result['scores'])\n",
        "    boxes.append(utils.extract_bboxes(mask))\n",
        "\n",
        "    temp_img = np.flipud(image)\n",
        "    result = model.detect([temp_img], verbose=0)[0]\n",
        "    mask = np.flipud(result['masks'])\n",
        "    masks.append(mask)\n",
        "    scores.append(result['scores'])\n",
        "    boxes.append(utils.extract_bboxes(mask))\n",
        "\n",
        "    angle = np.random.choice([1, -1])\n",
        "    temp_img = np.rot90(image, k=angle, axes=(0, 1))\n",
        "    result = model.detect([temp_img], verbose=0)[0]\n",
        "    mask = np.rot90(result['masks'], k=-angle, axes=(0, 1))\n",
        "    masks.append(mask)\n",
        "    scores.append(result['scores'])\n",
        "    boxes.append(extract_bboxes(mask))\n",
        "\n",
        "    masks = np.concatenate(masks, axis=-1)\n",
        "    scores = np.concatenate(scores, axis=-1)\n",
        "    boxes = np.concatenate(boxes, axis=0)\n",
        "\n",
        "    if (boxes.shape[0] > 0):\n",
        "      keep_ind = utils.non_max_suppression(boxes, scores, 0.1)\n",
        "      masks = masks[:, :, keep_ind]\n",
        "      scores = scores[keep_ind]\n",
        "\n",
        "    results['masks'] = masks\n",
        "    results['scores'] = scores\n",
        "\n",
        "    return result\n",
        "  \n",
        "def cluster_prediction(model, image):\n",
        "\n",
        "    \"\"\" Test time augmentation method using bounding box IoU\"\"\"\n",
        "    # from utils import non_max_suppression, extract_bboxes, compute_overlaps\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Predict masks on actual image\n",
        "    result1 = model.detect([image], verbose=0)[0]\n",
        "    # Handles no mask predictions\n",
        "    if result1['masks'].shape[0] == 0:\n",
        "        result1['masks'] = np.zeros([height, width, 1])\n",
        "        result1['masks'][0, 0, 0] = 1\n",
        "        result1['scores'] = np.ones(1)\n",
        "\n",
        "    # Predict masks on LR flipped image\n",
        "    temp_img = np.fliplr(image)\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.fliplr(result2['masks'])\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm].size != 0 and np.max(overlaps[mm]) > 0.1:\n",
        "            ind = np.argmax(overlaps[mm])\n",
        "            mask = result1['masks'][:, :, mm] + result2['masks'][:, :, ind]\n",
        "            result1['masks'][:, :, mm] = (mask > 0).astype(np.uint8)\n",
        "        else:\n",
        "            result1['masks'][:, :, mm] = 0\n",
        "\n",
        "    return result1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6h6dt7YeN4P6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def merge_cluster_prediction(model, image):\n",
        "\n",
        "    \"\"\" Test time augmentation method using bounding box IoU\"\"\"\n",
        "    # from utils import non_max_suppression, extract_bboxes, compute_overlaps\n",
        "    height, width = image.shape[:2]\n",
        "    class_names = ['BG', 'ship']\n",
        "    \n",
        "    instances_thresh = 0.2\n",
        "    instances_occur = 4\n",
        "    \n",
        "    # Predict masks on actual image\n",
        "    result1 = model.detect([image], verbose=0)[0]\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result1['masks'].shape[0] == 0:\n",
        "        result1['masks'] = np.zeros([height, width, 1])\n",
        "        result1['masks'][0, 0, 0] = 1\n",
        "        result1['scores'] = np.ones(1)\n",
        "        \n",
        "    instances = np.ones((result1['masks'].shape[2]))\n",
        "        \n",
        "\n",
        "      \n",
        "        \n",
        "    # Predict masks on LR flipped image\n",
        "    temp_img = np.fliplr(image)\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.fliplr(result2['masks'])\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "    \n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== LR')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    # Predict masks on UD flipped image\n",
        "    temp_img = np.flipud(image)\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.flipud(result2['masks'])\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "    \n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== UD')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "               \n",
        "    # Predict masks on LR-UD flipped image\n",
        "    temp_img = np.fliplr(np.flipud(image))\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.fliplr(np.flipud(result2['masks']))\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "\n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== LR-UD')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "            \n",
        "\n",
        "    # Predict masks on rot90 no flipped image\n",
        "    temp_img = np.rot90(image)\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.rot90(result2['masks'], k=-1)\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "\n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== rot90')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "                        \n",
        "            \n",
        "            \n",
        "            \n",
        "    # Predict masks on rot90 LR flipped image\n",
        "    temp_img = np.rot90(np.fliplr(image))\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.fliplr(np.rot90(result2['masks'], k=-1))\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "\n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== rot90-LR')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    # Predict masks on rot90 UD flipped image\n",
        "    temp_img = np.rot90(np.flipud(image))\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.flipud(np.rot90(result2['masks'], k=-1))\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "\n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== rot90-UD')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "            \n",
        "    # Predict masks on rot90 LR-UD flipped image\n",
        "    temp_img = np.rot90(np.fliplr(np.flipud(image)))\n",
        "    result2 = model.detect([temp_img], verbose=0)[0]\n",
        "    result2['masks'] = np.flipud(np.fliplr(np.rot90(result2['masks'], k=-1)))\n",
        "\n",
        "    # Handles no mask predictions\n",
        "    if result2['masks'].shape[0] == 0:\n",
        "        result2['masks'] = np.zeros([height, width, 1])\n",
        "        result2['masks'][0, 0, 0] = 1\n",
        "        result2['scores'] = np.ones(1)\n",
        "\n",
        "    # Compute IoU on masks\n",
        "    overlaps = utils.compute_overlaps_masks(result1['masks'], result2['masks'])\n",
        "\n",
        "    for mm in range(overlaps.shape[0]):\n",
        "        if overlaps[mm,:].size != 0 and np.max(overlaps[mm,:]) > instances_thresh:\n",
        "          instances[mm]=instances[mm]+1\n",
        "\n",
        "    for mm in range(overlaps.shape[1]):\n",
        "        if overlaps[:,mm].size != 0 and np.max(overlaps[:,mm]) == 0.0:\n",
        "#            print('=========== rot90-LR-UD')\n",
        "            m2 = np.expand_dims(result2['masks'][:, :, mm], axis=2)\n",
        "            result1['masks'] = np.append(result1['masks'], m2, axis = 2)\n",
        "            s2 = np.expand_dims(result2['scores'][mm], axis=0)\n",
        "            result1['scores'] = np.append(result1['scores'], s2, axis = 0)\n",
        "            r2 = utils.extract_bboxes(m2)\n",
        "            result1['rois'] = np.append(result1['rois'], r2, axis = 0)\n",
        "            c2 = np.expand_dims(result2['class_ids'][mm], axis=0)\n",
        "            result1['class_ids'] = np.append(result1['class_ids'], c2, axis = 0)\n",
        "            instances = np.append(instances, [1])\n",
        "            \n",
        "            \n",
        "\n",
        "\n",
        "            \n",
        "#    print(instances)\n",
        "    for mm in range(instances.shape[0]):\n",
        "        if(instances[mm]<instances_occur):\n",
        "          result1['masks'][:, :, mm] = 0\n",
        "          result1['rois'][mm] = utils.extract_bboxes(np.expand_dims(result1['masks'][:, :, mm], axis=2))\n",
        "#          print('INSTANCES',mm)\n",
        "            \n",
        "            \n",
        "            \n",
        "    return result1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BdcHJNEtkMzx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "class_names = ['BG', 'ship']\n",
        "\n",
        "def rotated_bounding_box(r, idx, image):\n",
        "  for mm in range(r['masks'].shape[2]):\n",
        "    img = r['masks'][:, :, mm]\n",
        "    img = np.array(img * 255, dtype = np.uint8)\n",
        "    _, contours,_ = cv2.findContours(img, 1, 2)\n",
        "    if len(contours) > 0:\n",
        "      cnt = contours[0]\n",
        "      rect = cv2.minAreaRect(cnt)\n",
        "      box = cv2.boxPoints(rect)\n",
        "      box = np.int0(box)\n",
        "      l1 = cv2.norm(box[0], box[1], normType=cv2.NORM_L2)\n",
        "      l2 = cv2.norm(box[1], box[2], normType=cv2.NORM_L2)\n",
        "\n",
        "      if l1+l2>150 and max(l1,l2)/min(l1,l2)<2.5:\n",
        "        #print(idx)\n",
        "        #print(r['scores'][mm])\n",
        "        #visualize.display_instances(\n",
        "        #    image, r['rois'], r['masks'], r['class_ids'],\n",
        "        #    class_names, r['scores'],\n",
        "        #    show_bbox=True, show_mask=False,\n",
        "        #    title=\"Prediction ORIGINAL\")\n",
        "        r['masks'][:, :, mm] = 0\n",
        "        r['rois'][mm] = utils.extract_bboxes(np.expand_dims(r['masks'][:, :, mm], axis=2))\n",
        "  return r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6FwwLZOjkS2W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#VISUALIZE SOME DETECTIONS\n",
        "\n",
        "detect_filename = os.path.join(RESULTS_DIR, 'detect_masks.csv')\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = ShipDataset()\n",
        "    dataset.load_ship(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    \n",
        "    #for idx in range(50,70):\n",
        "    for idx in [58,92,97,180,322,338,473,521,586,1028]:\n",
        "        image_id = dataset.image_ids[idx]\n",
        "        if (idx % 100==0):\n",
        "            print('Processed images: ', idx, ' - Time: ', datetime.datetime.now())\n",
        "        # Load image and run detection\n",
        "        image_file = dataset.image_info[image_id][\"id\"]+'.jpg'\n",
        "        image = dataset.load_image(image_id)\n",
        "\n",
        "        r = model.detect([image], verbose=0)[0]\n",
        "        visualize.display_instances(\n",
        "        image, r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=True, show_mask=False,\n",
        "        title=\"Prediction ORIGINAL\", captions=['0','1','2','3','4','5','6','7','8','9'])\n",
        "        \n",
        "        r = merge_cluster_prediction(model, image)\n",
        "        #r = rotated_bounding_box(r, idx, image)\n",
        "        visualize.display_instances(\n",
        "        image, r['rois'], r['masks'], r['class_ids'],\n",
        "        dataset.class_names, r['scores'],\n",
        "        show_bbox=True, show_mask=False,\n",
        "        title=\"Prediction NEW\")\n",
        "\n",
        "        \n",
        "config = InferenceConfig()\n",
        "#config.display()\n",
        "\n",
        "#modelFilePath = model.find_last()\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "print(\"Loading weights \", modelFilePath)\n",
        "model.load_weights(modelFilePath, by_name=True)\n",
        "\n",
        "#detect(model=model, dataset_dir=DATASET_DIR, subset=\"val\")\n",
        "detect(model=model, dataset_dir=DATASET_DIR, subset=\"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ifzyeW1YJ20",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# RUN DETECTION\n",
        "\n",
        "detect_filename = os.path.join(RESULTS_DIR, 'detect_masks.csv')\n",
        "\n",
        "def detect(model, dataset_dir, subset):\n",
        "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
        "    print(\"Running on {}\".format(dataset_dir))\n",
        "\n",
        "    # Create directory\n",
        "    if not os.path.exists(RESULTS_DIR):\n",
        "        os.makedirs(RESULTS_DIR)\n",
        "\n",
        "    # Read dataset\n",
        "    dataset = ShipDataset()\n",
        "    dataset.load_ship(dataset_dir, subset)\n",
        "    dataset.prepare()\n",
        "    # Load over images\n",
        "    submission = []\n",
        "    last_idx = len(dataset.image_ids)\n",
        "    print('Dataset length:',last_idx)\n",
        "    for idx in range(last_idx):\n",
        "        image_id = dataset.image_ids[idx]\n",
        "        if (idx % 20==0):\n",
        "            print('Processed images: ', idx, ' - Time: ', datetime.datetime.now())\n",
        "        # Load image and run detection\n",
        "        image = dataset.load_image(image_id)\n",
        "        image_file = dataset.image_info[image_id][\"id\"]+'.jpg'\n",
        "        # Detect objects\n",
        "        #r = model.detect([image], verbose=0)[0]\n",
        "        r = merge_cluster_prediction(model, image)\n",
        "        \n",
        "        r = rotated_bounding_box(r, idx, image)\n",
        "\n",
        "        # Encode image to RLE. Returns a string of multiple lines\n",
        "        rle = mask_to_rle(image_file, r[\"masks\"], r[\"scores\"])\n",
        "        submission.append(rle)\n",
        "        # Save image with masks\n",
        "#        visualize.display_instances(\n",
        "#            image, r['rois'], r['masks'], r['class_ids'],\n",
        "#            dataset.class_names, r['scores'],\n",
        "#            show_bbox=False, show_mask=False,\n",
        "#            title=\"Predictions\")\n",
        "        plt.savefig(\"{}/{}.png\".format(RESULTS_DIR, dataset.image_info[image_id][\"id\"]))\n",
        "\n",
        "    # Save to csv file\n",
        "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
        "    with open(detect_filename, \"w\") as f:\n",
        "        f.write(submission)\n",
        "    print(\"Saved to\", detect_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIyzG0_YSSFS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "#modelFilePath = model.find_last()\n",
        "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
        "\n",
        "print(\"Loading weights \", modelFilePath)\n",
        "model.load_weights(modelFilePath, by_name=True)\n",
        "\n",
        "#detect(model=model, dataset_dir=DATASET_DIR, subset=\"val\")\n",
        "detect(model=model, dataset_dir=DATASET_DIR, subset=\"test\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHrokUTDsKEj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from shutil import copy\n",
        "\n",
        "submit_file = 'submit.csv'\n",
        "copy(detect_filename, submit_file)\n",
        "\n",
        "df = pd.read_csv(submit_file)\n",
        "exludedAndProcessedFiles = df['ImageId'].unique().tolist()\n",
        "print(len(exludedAndProcessedFiles))\n",
        "noship_files = ''\n",
        "test_files = next(os.walk('test/noship'))[2]\n",
        "print(len(test_files))\n",
        "for filename in test_files:\n",
        "    if (filename not in exludedAndProcessedFiles):\n",
        "        noship_files+='\\n'+filename+','\n",
        "\n",
        "with open(submit_file, 'a') as f:\n",
        "    f.write(noship_files)\n",
        "print(\"Saved to \", submit_file)\n",
        "files.download(submit_file)\n",
        "files.download(detect_filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LqpCFRHbL3KJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#VISUALIZE TEST\n",
        "\n",
        "%cd\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "masks = pd.read_csv(detect_filename)\n",
        "print(masks['ImageId'].value_counts().shape[0], 'images found in csv, an image can have multiple masks for multiple ship, or not ship (NaN EncodedPixels)')\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "dataset = ShipDataset()\n",
        "dataset.load_ship(DATASET_DIR, subset=\"test\")\n",
        "\n",
        "# Must call before using the dataset\n",
        "dataset.prepare()\n",
        "\n",
        "print(\"Image Count: {}\".format(len(dataset.image_ids)))\n",
        "print(\"Class Count: {}\".format(dataset.num_classes))\n",
        "for i, info in enumerate(dataset.class_info):\n",
        "    print(\"{:3}. {:50}\".format(i, info['name']))\n",
        "    \n",
        "image_ids = np.random.choice(dataset.image_ids, 4)\n",
        "for image_id in image_ids:\n",
        "    image_file = \"{}.jpg\".format(dataset.image_info[image_id]['id'])\n",
        "    image = dataset.load_image(image_id)\n",
        "    mask, class_ids = dataset.load_mask(image_id)\n",
        "    print(image_file, class_ids.size)\n",
        "    if class_ids.size != 0:\n",
        "        visualize.display_top_masks(image, mask, class_ids, dataset.class_names, limit=1)\n",
        "    else:\n",
        "        visualize.display_images([image], cols = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}